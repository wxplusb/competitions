## Категоризация товаров от KazanExpress

### Задача

Необходимо предсказать категорию товара на маркетплейсе на основе его заголовка, описания, картинки, различных атрибутов, а также названия магазина.

### Решение

Данная задача - это мультимодальная (текст, изображения, табличные данные) мультиклассовая классификация. Для ее решения выделяют два подхода [researchgate](https://www.researchgate.net/publication/347688606_Image_and_Text_fusion_for_UPMC_Food-101_using_BERT_and_CNNs): 
- early fusion - когда получают фичи от текстовой модели и фичи от image модели, затем на них обучают классификатор
- late fusion - получают предсказания (например вероятности) от текстовой и image модели, затем  обучают классификатор.
Чаще early fusion показывает себя лучше, так как больше пространство для поиска взаимодействий между фичами разных модальностей. Что касается классификатора, то создатель библиотеки для мультимодальных задач pytorch-widedeep пишет [github](https://github.com/jrzaurin/tabulardl-benchmark), что бустинги пока выигрывают у DL в похожих случаях. 
- Я реализовывал early fusion в разных вариантах.

1) [1_eda_baseline.ipynb](1_eda_baseline.ipynb) Сначала я посмотрел подготовил данные и обучил в качестве бейзлайна fasttext (f1 ~ 0.85)

2) [2_get_embeds.ipynb](2_get_embeds.ipynb) Далее на 5 фолдах сделал fine-tuning берта на текстовых данных (f1 ~ 0.88-0.89) и для каждого фолда извлек эмбеддинги и сохранил их. Также для изображений сделал fine-tuning EfficientNet_B0 (f1 ~ 0.61-0.63) и для каждого фолда извлек эмбеддинги и сохранил их. Версию берта 'cointegrated/LaBSE-en-ru' выбрал на основании рейтинга [github](https://github.com/avidale/encodechka) и учитывая скорость обучения и то что она рус-англ. 

3) [3_train_boosting.ipynb](3_train_boosting.ipynb) Полученные эмбеддинги я сконкатенировал и дальше уменьшал размерность с помощью umap и PCA (хотя она для нелинейных зависимостей неочень подходит), я пробовал как по отдельности уменьшать размерность каждого из двух эмбеддингов, так и вместе. Дальше обучал catboost, py_boost (gpu бустинг специально для случаев когда много классов, обучается быстрее). Но так как это медленно, то оптимальные гиперпараметры для umap или отбор признаков для catboost, не получилось сделать. Лучший f1 ~ 0.87 не дотягивал до соло берта. Тут можно было в рамках тренировки берта и EfficientNet делать эмбеддинги сразу размером 20-30, чтобы обойтись без umap.

4) [4_train_mlp_resnet_ftt.ipynb](4_train_mlp_resnet_ftt.ipynb) После бустингов на этих эмбеддингах попробовал DL модели для табличных данных: MLP, ResNet, FTT Transformer. MLP, ResNet обучаются очень быстро. Но все трое тоже выше f1 ~ 0.89 не показали.

5) На данном этапе я сделал предварительный вывод, что эмбеддинги текста и эмбеддинги изображений, в том виде как я их получил и в данной задаче, не несут друг для друга дополнительных фичей, которые помогли бы улучшить f1 в совокупности, потому что каждый эмбеддинг был получен в тренировке на классификацию, и поэтому он по отдельности несет с собой фичи, которые важны для классификации, но не семантические фичи. Например, ручка и тетрадка принадлежат категории Канцелярия, но ручка и тетрадка разные вещи, имеют разный смысл и вид. То есть к моим эмбеддингам для лучшего результата можно было добавить эмбеддинги несущие семантику, например от моделей CLIP (RuCLIP).

6) [5_train_huse.ipynb](5_train_huse.ipynb) Дальше я сделал модель, в которой одновременно fine-tuning-ились берт и EfficientNet (классы TextTower и ImageTower), взяв за основу модель HUSE [arxiv](https://arxiv.org/pdf/1911.05978.pdf), но с различиями: авторы подавали на вход готовые семантические эмбеддинги Graph-RISE, а я тренировал их в процессе, и в архитектуре у них было много линейных слоев, я это не использовал. Дальше выходы берта и EfficientNet я конкатенировал вместе с эмбеддингом магазина и передавал на вход лосс-функции BigLoss, состоящей из 3 мини лосс-функций:
- классификационная CrossEntropyLoss
- CrossModalGapLoss, следящая, чтобы для одного образца его текстовый эмбеддинг был близок к его эмбеддингу изображения в универсальном пространстве нормализованных эмбеддингов.
- SemanticSimilarityLoss - нужна для того, чтобы образцы двух похожих классов (например одежда мужская и одежда женская) были в пространстве эмбеддингом ближе друг к другу, чем например к образцам с далекими по смыслу классами (к классам электроника и телефоны). Для ее вычисления вычислялась матрица смежности на основе берт-эмбедингов названий категорий.
Эта модель показала f1 ~ 0.87, можно наверное улучшить подобрав более тщательно веса каждой мини-лосс-функции и использовать не конкатенацию фич, а что-то по-сложнее, типа TabNet. И вероятно вклад модели на изображениях невелик, так как на нескольких моделях не было заметно сдвигов.

7) В итоге для финального сабмита я использовал соло-берт на 5 фолдах из ноутбука [2_get_embeds.ipynb](2_get_embeds.ipynb).

Файлы:
1. [src/data.py](src/data.py) - классы на основе pytorch Dataset, pl.LightningDataModule для моделей DL, разбивка на фолды, создание dataloaders
2. [src/models.py](src/models.py) - модели nn.Module для берта, mlp, EfficientNet 
3. [src/net.py](src/net.py) - классы pl.LightningModule, содержащие training, validation loops, configure optimizers
4. [src/huse.py](src/huse.py) - выделил отдельный файл для всех компоненов модели HUSE, чтобы не смешивать с другими
5. [src/losses.py](src/losses.py) - лосс функции в модели HUSE
6. [src/my.py](src/my.py) и [src/text_utils.py](src/text_utils.py) -  утилиты

### Результат:

```
1 место
```