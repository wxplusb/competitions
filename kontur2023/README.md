## Извлечение текстовых фрагментов из документов по меткам от Kонтур

### Задача

В Контуре мы много работаем с документами: арбитражные иски, госзакупки, исполнительные производства. В данном задании мы предлагаем вам сделать модель, которая поможет отделу госзакупок извлекать 
нужный кусок текста из документа для того, чтобы сформировать анкету заявки. То, какой именно фрагмент текста нужно извлечь, зависит от пункта анкеты, соответствующего документу.
Всего в каждом документе, с которыми вы будет работать, есть 1 из 2-х пунктов анкеты, по которым необходимо извлекать кусочки из текста:
- обеспечение исполнения контракта
- обеспечение гарантийных обязательств

Соответственно, ваша модель, принимая на вход `текст документа` и `наименование одного из двух пунктов`, должна возвращать `соответствующий кусочек текста из текста документа`.

### Решение

Данную задачу я решал как Extractive Question Answering, рассматривая текст документа как context, label как вопрос question, нужный кусок текста как answer. Для этой задачи одно из популярных решений, основано на берте, к нему добавляется линейный слой - получается модель BertForQuestionAnswering (AutoModelForQuestionAnswering), которая для каждого токена в контексте предсказывает два значения, логитса, показывающие степень уверенности, что этот токен является или началом или концом нужного нам ответа в контексте соответственно.
На вход модели подавались токенизированные вопрос и контекст и таргеты - начальные и конечные позиции ответа. Если контекст был длиной больше, чем мог принять берт, то он разбивался на куски. Далее перебирались различные комбинации токенов для начала ответа и для конца ответа, для каждой комбинации находилась сумма логитсов для начального и конечного токена, по наибольшей сумме выбирался наиболее вероятный ответ из контекста, и также топ ответов. Для случая, когда в контексте нет ответа, в комбинации добавлялось минимальное предсказание для пустого ответа по всем кускам данного контекста.
Валидация проводилась на комбинированной метрике Accuracy на топ 1 и топ 5 наиболее вероятных ответов.
Берт файн-тюнился на 5 фолдах, с каждого фолда получали топ 5 ответов с рейтингом каждого ответа. По сумме рейтинга по всем фолдам выбирался финальный кусочек для данного документа.

Файлы:
1. [extract.ipynb](extract.ipynb) - Eda, предобработка, тренировка моделей, объединение предсказаний с разных фолдов.
2. [qa.py](qa.py) - основные функции для подготовки данных к тренировке, валидации и постобработке.
3. [my.py](my.py) -  утилиты для фолдов, памяти и т.д.

### Результат:

```
2-3 место
```